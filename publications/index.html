<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->

  <!-- Website verification -->
  
    <meta name="google-site-verification" content="">
  
  
  <!--
    Avoid warning on Google Chrome Error with Permissions-Policy header:
    Origin trial controlled feature not enabled: 'interest-cohort'.
    see https://stackoverflow.com/a/75119417
  -->
  <meta http-equiv="Permissions-Policy" content="interest-cohort=()">




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      publications | Zhaolun Will Su
    
  
</title>
<meta name="author" content="Zhaolun Su">
<meta name="description" content="Publications organized by research topics">

  <meta name="keywords" content="Zhaolun Will Su, Meta FAIR, LLM, Large Language Models, Vision Language Models, AI Research, Machine Learning, NLP, Reasoning, Alignment">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">



<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->




  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%92%AD&lt;/text&gt;&lt;/svg&gt;">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="https://zhsu-private.github.io/publications/">


  <!-- Dark Mode -->
  <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script>
  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script>
    initTheme();
  </script>










  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/">
          Zhaolun Will Su
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">home
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                
                <li class="nav-item ">
                  <a class="nav-link" href="/news/">news
                    
                  </a>
                </li>
              
            
          
            
          
            
          
            
          
          
            <!-- Search -->
            <li class="nav-item">
              <button id="search-toggle" title="Search" onclick="openSearchModal()">
                <span class="nav-link">ctrl k <i class="ti ti-search"></i></span>
              </button>
            </li>
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="ti ti-sun-moon" id="light-toggle-system"></i>
                <i class="ti ti-moon-filled" id="light-toggle-dark"></i>
                <i class="ti ti-sun-filled" id="light-toggle-light"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        

<div class="post">
  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">Publications organized by research topics</p>
  </header>

  <article>
    <h2 id="improving-llm-reasoning-ability">Improving LLM Reasoning Ability</h2>

<p><strong>Moving Beyond Binary Verifiable Reward</strong><br>
Leitian Tao, Ilia Kulikov, Jason Weston, Ping Yu<br>
<em>2025</em> [Upcoming]</p>

<p>Current research on reasoning tasks mainly focuses on verifiable rewards. We studied whether using verifiable answers for GRPO can help with hard-to-verify reasoning tasks, and explored whether including hard-to-verify training data is necessary. We proposed combining reward model signals with rule-based signals for model training, which allows the reward signal to account for intermediate reasoning steps while avoiding the issue of reward hacking that arises when relying solely on reward models.</p>

<hr>

<p><strong>Distilling System 2 into System 1</strong><br>
Ping Yu, Jing Xu, Jason Weston, Ilia Kulikov<br>
<em>2024</em> [<a href="link">PDF</a>]</p>

<p>Investigate self-supervised methods to ‘compile” (distill) higher quality outputs from System 2 techniques back into LLM generations without intermediate reasoning token sequences, as this reasoning has been distilled into System 1.</p>

<hr>

<h2 id="data-quality-improvement--synthetic-data-generation">Data Quality Improvement &amp; Synthetic Data Generation</h2>

<p><strong>CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks</strong><br>
Ping Yu, Jack Lanchantin, Tianlu Wang, et al.<br>
<em>2025</em> [<a href="link">PDF</a>]</p>

<p>Proposed CoT-Self-Instruct, a synthetic data generation method that uses Chain-of-Thought reasoning and automatic filtering to create high-quality training data. Achieves state-of-the-art results on verifiable reasoning benchmarks (MATH500, AMC23, AIME24, GPQA-Diamond) and surpasses human and standard Self-Instruct data on AlpacaEval 2.0 and Arena-Hard.</p>

<hr>

<p><strong>RIP: Better models by survival of the fittest prompts</strong><br>
Ping Yu, Weizhe Yuan, et al.<br>
<em>ICML 2025</em> [<a href="link">PDF</a>]</p>

<p>Proposed Rejecting Instruction Preferences (RIP), a data filtering method that evaluates training prompts via rejected response quality and reward gap between chosen/rejected outputs. Achieved large gains in model performance: +9.4% AlpacaEval2, +8.7% Arena-Hard, +9.9% WildBench (Llama-3.1-8B); and boosted Llama-3.3-70B Arena-Hard accuracy from 67.5→82.9 (18th→6th place).</p>

<hr>

<p><strong>Self-alignment with instruction backtranslation</strong><br>
Xian Li, Ping Yu, Chunting Zhou, et al.<br>
<em>ICLR 2024 (Oral)</em> [<a href="link">PDF</a>]</p>

<p>Developed instruction backtranslation, a scalable method to train instruction-following LLMs by automatically generating and curating instruction–response pairs from web text.</p>

<hr>

<h2 id="self-improvement">Self-Improvement</h2>

<p><strong>ReStrain: Reinforcement with Self-Restraint training on Reasoning Tasks</strong><br>
Zhaoning Yu*, Zhaolun Su*, Haozhu Wang, Jason Weston, Ping Yu*, Jing Xu*<br>
<em>2025</em> [Upcoming]</p>

<p>Introduced RESTRAIN, a self-penalizing RL framework that transforms unlabeled data into training signals by penalizing overconfident or low-confidence rollouts while preserving promising reasoning chains. RESTRAIN integrates with policy optimization (e.g., GRPO) and achieves large gains on challenging reasoning benchmarks, narrowing the gap with supervised training.</p>

<hr>

<p><strong>Shepherd: A critic for language model generation</strong><br>
Tianlu Wang*, Ping Yu*, Ellen Tan, et al.<br>
<em>2023</em> [<a href="link">PDF</a>]</p>

<p>Introduced Shepherd, a 7B-parameter LLM tuned to critique and refine model outputs using a curated feedback dataset. Shepherd’s critiques match or surpass those of larger models, achieving 53–87% win rates against competitive alternatives and rivaling ChatGPT in human evaluation.</p>

<hr>

<h2 id="llm-as-judge">LLM as Judge</h2>

<p><strong>J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning</strong><br>
Chenxi Whitehouse, Tianlu Wang, Ping Yu, et al.<br>
<em>2025</em> [<a href="link">PDF</a>]</p>

<p>Introduced J1, a reinforcement learning approach for training LLM-as-a-Judge with verifiable rewards that incentivize reasoning and reduce bias. J1 outperforms all existing 8B/70B models (including DeepSeek-R1 distillations), surpasses o1-mini, and even beats R1 on some benchmarks, demonstrating stronger judgment ability through improved chain-of-thought reasoning.</p>

<hr>

<p><strong>Self-taught evaluators</strong><br>
Tianlu Wang, Ilia Kulikov*, Olga Golovneva*, Ping Yu*, et al.<br>
<em>2024</em> [<a href="link">PDF</a>]</p>

<p>Proposed Self-Taught Evaluator, a synthetic-data approach for training LLM-as-a-Judge without human labels. Through iterative self-improvement with reasoning traces and judgments, improved LLaMA3-70B-Instruct from 75.4 → 88.3 on RewardBench, surpassing GPT-4 and matching top reward models trained with human preferences.</p>

<hr>

<h2 id="others">Others</h2>

<p><strong>Chameleon: Mixed-modal early-fusion foundation models</strong><br>
Chameleon team<br>
<em>2024</em> [<a href="link">PDF</a>]</p>

<p>Developed Chameleon, a family of early-fusion token-based multimodal models for unified image–text understanding and generation. Chameleon achieves state-of-the-art results in image captioning, surpasses LLaMA-2 on text tasks, competes with Mixtral 8x7B and Gemini-Pro, and matches/exceeds much larger models like GPT-4V in human evaluations of long-form mixed-modal generation.</p>

<hr>

<p><strong>OPT-IML: Scaling language model instruction meta learning through the lens of generalization</strong><br>
OPT team<br>
<em>2022</em> [<a href="link">PDF</a>]</p>

<p>Developed OPT-IML Bench, a large benchmark of 2,000 NLP tasks for studying instruction-tuning decisions (task diversity, sampling, demonstrations, objectives). Using this framework, trained OPT-IML 30B and 175B, showing improved generalization across unseen categories, tasks, and instances, and significantly outperforming OPT on multiple benchmarks.</p>

  </article>

  

  
</div>

      
    </div>

    <!-- Footer -->
    


  <footer class="fixed-bottom" role="contentinfo">
    <div class="container mt-0">
      
  © Copyright 2025
  Zhaolun
  
  Su. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

  
  

    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>


  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script>























  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>






<!-- Load Common JS -->
<script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script>
<script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script>
<script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script>

<!-- Jupyter Open External Links New Tab -->
<script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>

<!-- Badges -->

  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>


  <script async src="https://badge.dimensions.ai/badge.js"></script>



  <!-- MathJax -->
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script>
  
    <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script>
    <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script>
  









  <!-- Scrolling Progress Bar -->
  <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script>







  <!-- Back to Top -->
  <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script>
  <script>
    addBackToTop();
  </script>



  <!-- Search -->
  <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script>
  <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys>
  <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script>
  <script src="/assets/js/search-data.js"></script>
  <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script>




  </body>
</html>
